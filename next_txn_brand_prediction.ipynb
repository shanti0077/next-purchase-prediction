{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZKA-a3qDtbs",
        "outputId": "8cb9d367-1b27-427c-eb68-dc09d3d6198a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         user_id            brand transaction_date\n",
            "0      CUST_3979           Swiggy       2023-10-31\n",
            "1       CUST_678         Bewakoof       2024-05-14\n",
            "2      CUST_2199  The Man Company       2023-09-17\n",
            "3      CUST_2011         Colorbar       2024-06-04\n",
            "4       CUST_879          CureFit       2023-10-03\n",
            "...          ...              ...              ...\n",
            "49995  CUST_1651          Goibibo       2023-07-08\n",
            "49996  CUST_4412      Craftsvilla       2023-12-26\n",
            "49997  CUST_4147        Mamaearth       2024-03-05\n",
            "49998  CUST_1406         Flipkart       2024-01-23\n",
            "49999  CUST_1505         Lenskart       2023-09-19\n",
            "\n",
            "[50000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "\n",
        "# List of top e-commerce brands in India\n",
        "top_ecommerce_brands_india = [\n",
        "    \"Amazon\", \"Flipkart\", \"Myntra\", \"Snapdeal\", \"TataCliq\", \"Paytm Mall\", \"AJIO\", \"ShopClues\",\n",
        "    \"BigBasket\", \"Grofers\", \"Reliance Fresh\", \"More Supermarket\", \"Spencer's\", \"Big Bazaar\", \"DMart\", \"Metro Cash and Carry\",\n",
        "    \"PharmEasy\", \"Medlife\", \"1mg\", \"Netmeds\", \"Apollo Pharmacy\", \"MedPlus\",\n",
        "    \"Nykaa\", \"Purplle\", \"Zivame\", \"Lenskart\", \"Beardo\", \"Mamaearth\", \"Wow Skin Science\", \"Bombay Shaving Company\",\n",
        "    \"The Man Company\", \"SUGAR Cosmetics\", \"Kama Ayurveda\", \"Forest Essentials\", \"Colorbar\", \"Lakme\", \"VLCC\",\n",
        "    \"Lotus Herbals\", \"Biotique\", \"Khadi Natural\",\n",
        "    \"FirstCry\", \"BabyChakra\", \"Hopscotch\",\n",
        "    \"Pepperfry\", \"Urban Ladder\", \"Home Centre\", \"Hometown\", \"Livspace\",\n",
        "    \"Croma\", \"Reliance Digital\", \"Vijay Sales\", \"Poorvika Mobiles\", \"Sangeetha Mobiles\", \"Pai International\",\n",
        "    \"Ezone\", \"Gadget 360\", \"Headphone Zone\",\n",
        "    \"Zomato\", \"Swiggy\", \"Faasos\", \"FreshMenu\", \"Box8\", \"Behrouz Biryani\", \"Dunzo\",\n",
        "    \"CureFit\", \"HealthifyMe\", \"1Wellness\", \"Healthkart\",\n",
        "    \"Amazon\", \"Flipkart\", \"Snapdeal\", \"Crossword\", \"SapnaOnline\", \"Infibeam\", \"BookMyShow\",\n",
        "    \"CaratLane\", \"Bluestone\", \"Voylla\",\n",
        "    \"MakeMyTrip\", \"Yatra\", \"Cleartrip\", \"Goibibo\", \"RedBus\", \"IRCTC\",\n",
        "    \"Heads Up For Tails\", \"Petsworld\", \"DogSpot\",\n",
        "    \"UrbanClap\", \"Furlenco\", \"Rentomojo\", \"Craftsvilla\", \"FabIndia\", \"Limeroad\", \"Clovia\", \"Bewakoof\"\n",
        "]\n",
        "\n",
        "# Number of transactions and unique customers\n",
        "num_transactions = 50000\n",
        "num_customers = 5000\n",
        "\n",
        "# Generate customer IDs\n",
        "customer_ids = [f\"CUST_{i+1}\" for i in range(num_customers)]\n",
        "\n",
        "# Generate synthetic transaction data\n",
        "data = []\n",
        "for _ in range(num_transactions):\n",
        "    customer_id = random.choice(customer_ids)\n",
        "    brand = random.choice(top_ecommerce_brands_india)\n",
        "    txn_date = datetime.now() - timedelta(days=random.randint(1, 365))  # Random date within the past year\n",
        "    data.append([customer_id, brand, txn_date.strftime('%Y-%m-%d')])\n",
        "\n",
        "# Convert to a DataFrame\n",
        "df = pd.DataFrame(data, columns=['user_id', 'brand', 'transaction_date'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYDPq07EHyDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the brands\n",
        "label_enc = LabelEncoder()\n",
        "df['brand_encoded'] = label_enc.fit_transform(df['brand'])\n",
        "\n",
        "# Prepare sequences for each customer\n",
        "def prepare_sequences(df, n_steps):\n",
        "    sequences = []\n",
        "    for _, group in df.groupby('user_id'):\n",
        "        brand_sequence = list(group['brand_encoded'])\n",
        "        for i in range(1, len(brand_sequence)):\n",
        "            if i + n_steps <= len(brand_sequence):\n",
        "                sequences.append(brand_sequence[i:i+n_steps])\n",
        "    return np.array(sequences)\n",
        "\n",
        "n_steps = 6  # Number of time steps to consider\n",
        "sequences = prepare_sequences(df, n_steps)"
      ],
      "metadata": {
        "id": "HGYsPlq-D8UA"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxuzIBfrEUAb",
        "outputId": "3283e262-ebca-4bbf-b7aa-c7518ed5cf3b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         user_id        brand transaction_date  brand_encoded\n",
            "0      CUST_4790       Swiggy       2024-03-20             80\n",
            "1       CUST_914        DMart       2023-12-16             24\n",
            "2      CUST_3344        IRCTC       2024-05-22             45\n",
            "3      CUST_4001   MakeMyTrip       2024-03-25             54\n",
            "4      CUST_3828     Flipkart       2023-08-22             31\n",
            "...          ...          ...              ...            ...\n",
            "49995  CUST_3579  SapnaOnline       2024-02-17             76\n",
            "49996  CUST_1291   BabyChakra       2024-05-04              5\n",
            "49997  CUST_2628        Nykaa       2024-01-13             62\n",
            "49998  CUST_1806      CureFit       2024-04-01             23\n",
            "49999  CUST_1377    ShopClues       2024-04-26             77\n",
            "\n",
            "[50000 rows x 4 columns]\n",
            "[[38 82 13 43 48 37]\n",
            " [82 13 43 48 37 51]\n",
            " [13 43 48 37 51 12]\n",
            " ...\n",
            " [85 49 29  6 34 79]\n",
            " [49 29  6 34 79 42]\n",
            " [29  6 34 79 42 88]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pad sequences to have the same length\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# The pad_sequences function is a utility function provided by Keras\n",
        "# that is used to ensure that all sequences in a list have the same length\n",
        "# Split sequences into input (X) and output (y)\n",
        "X, y0 = sequences_padded[:, :-1], sequences_padded[:, -1]\n",
        "\n",
        "# One-hot encode the output\n",
        "y = to_categorical(y0, num_classes=len(label_enc.classes_))\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(label_enc.classes_), output_dim=50, input_length=X.shape[1]))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(len(label_enc.classes_), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KZ06nsVfD8Ok"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCSMw7HkGT20",
        "outputId": "4e663b27-234e-4787-da71-d9c1b0fb5867"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[38 82 13 43 48]\n",
            " [82 13 43 48 37]\n",
            " [13 43 48 37 51]\n",
            " ...\n",
            " [85 49 29  6 34]\n",
            " [49 29  6 34 79]\n",
            " [29  6 34 79 42]]\n",
            "[37 51 12 ... 79 42 88]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape  )\n",
        "\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWDZPqLiFzK8",
        "outputId": "7440729d-62ed-4d45-bb8e-cb59fa376c54"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16405, 5)\n",
            "(4102, 5)\n",
            "(16405, 92)\n",
            "(4102, 92)\n",
            "[[73 33 58 72 71]\n",
            " [79 19 71 20 53]\n",
            " [ 9 22  4 79  9]\n",
            " ...\n",
            " [62 80 69  2 82]\n",
            " [38 47 34 72 72]\n",
            " [11 25  3 70 42]]\n",
            "[[69 45  8 10 44]\n",
            " [28 18 89 24 31]\n",
            " [49 54 56 17 58]\n",
            " ...\n",
            " [18  2  1 45 69]\n",
            " [38 57  7 83 78]\n",
            " [35 66  4 70  6]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h04GLgAJD8IA",
        "outputId": "e0711cb7-bfd0-4b5b-87bc-cadfec1d7a61"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "257/257 [==============================] - 7s 17ms/step - loss: 4.5156 - accuracy: 0.0196 - val_loss: 4.5093 - val_accuracy: 0.0212\n",
            "Epoch 2/10\n",
            "257/257 [==============================] - 3s 11ms/step - loss: 4.5062 - accuracy: 0.0224 - val_loss: 4.5106 - val_accuracy: 0.0236\n",
            "Epoch 3/10\n",
            "257/257 [==============================] - 3s 11ms/step - loss: 4.4957 - accuracy: 0.0259 - val_loss: 4.5189 - val_accuracy: 0.0219\n",
            "Epoch 4/10\n",
            "257/257 [==============================] - 3s 11ms/step - loss: 4.4760 - accuracy: 0.0267 - val_loss: 4.5305 - val_accuracy: 0.0209\n",
            "Epoch 5/10\n",
            "257/257 [==============================] - 5s 18ms/step - loss: 4.4537 - accuracy: 0.0282 - val_loss: 4.5504 - val_accuracy: 0.0192\n",
            "Epoch 6/10\n",
            "257/257 [==============================] - 3s 11ms/step - loss: 4.4281 - accuracy: 0.0321 - val_loss: 4.5648 - val_accuracy: 0.0185\n",
            "Epoch 7/10\n",
            "257/257 [==============================] - 3s 11ms/step - loss: 4.4011 - accuracy: 0.0350 - val_loss: 4.5796 - val_accuracy: 0.0156\n",
            "Epoch 8/10\n",
            "257/257 [==============================] - 3s 11ms/step - loss: 4.3727 - accuracy: 0.0398 - val_loss: 4.6120 - val_accuracy: 0.0143\n",
            "Epoch 9/10\n",
            "257/257 [==============================] - 4s 15ms/step - loss: 4.3425 - accuracy: 0.0401 - val_loss: 4.6359 - val_accuracy: 0.0129\n",
            "Epoch 10/10\n",
            "257/257 [==============================] - 3s 12ms/step - loss: 4.3084 - accuracy: 0.0452 - val_loss: 4.6619 - val_accuracy: 0.0124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5685517430>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_test_decoded = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCkDVEMoD8Bz",
        "outputId": "5b4b7afc-cbf0-4d7e-b119-7f5a8541101c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDnpc-rneBsw",
        "outputId": "a45056da-40c4-4288-f56e-425971f4f1da"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[45 34 74 ... 13 69 45]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF13M7EzeGiL",
        "outputId": "ff3e5911-8fc4-4d24-bc29-705f3476d7a2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[74 43 46 ... 86  3 77]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_decoded, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTlNX-7Vcykp",
        "outputId": "40ba4979-f719-422b-86c3-e2105adc1dd3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 1 0]\n",
            " [0 0 0 ... 1 0 1]\n",
            " ...\n",
            " [0 0 1 ... 0 1 0]\n",
            " [0 0 2 ... 0 0 0]\n",
            " [0 0 1 ... 0 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conf_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L580qdqdCaP",
        "outputId": "854d2666-9ecd-4545-829c-0c247f1af930"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(92, 92)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test_decoded, y_pred, average='weighted')\n",
        "recall = recall_score(y_test_decoded, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test_decoded, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHmTJFGipF0F",
        "outputId": "f8fe8e72-e81d-423e-a9f5-d7be7367941e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.010211932550116815, Recall: 0.01240272373540856, F1 Score: 0.008605248175606817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the next n unique brands for each customer\n",
        "def predict_next_n_unique_brands(model, sequence, n):\n",
        "    predictions = []\n",
        "    predicted_classes = set()  # Set to keep track of predicted classes\n",
        "    while len(predictions) < n:\n",
        "        prediction = model.predict(np.array(sequence).reshape(1, -1))[0]\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        if predicted_class not in predicted_classes:\n",
        "            predictions.append(label_enc.inverse_transform([predicted_class])[0])\n",
        "            predicted_classes.add(predicted_class)\n",
        "        sequence = np.append(sequence[1:], predicted_class)\n",
        "    return predictions\n",
        "\n",
        "# Example: Predict the next 5 unique brands for the first customer in the test set\n",
        "sequence = X_test[0]\n",
        "predicted_brands = predict_next_n_unique_brands(model, sequence, 5)\n",
        "print(\"Predicted Brands:\", predicted_brands)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOtjXe-gZsJH",
        "outputId": "ccd2de8b-3e66-4a76-da8f-89027b9b09f9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicted Brands: ['SUGAR Cosmetics', 'Goibibo', 'Amazon', 'Yatra', 'Faasos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store individual customer results\n",
        "results = []\n",
        "\n",
        "# Iterate over the first 10 unique customers\n",
        "for user_id in df['user_id'].unique()[:10]:\n",
        "    # Filter data for the current customer\n",
        "    user_data = df[df['user_id'] == user_id]\n",
        "\n",
        "    # Prepare sequences for the current customer\n",
        "    sequences = prepare_sequences(user_data, n_steps)\n",
        "    sequences_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Predict the next 5 brands\n",
        "    if len(sequences_padded) > 0:\n",
        "        first_sequence = sequences_padded[0]\n",
        "        next_5_predicted_brands = predict_next_n_unique_brands(model, first_sequence, 5)\n",
        "    else:\n",
        "        next_5_predicted_brands = []\n",
        "\n",
        "    # Append the results for the current customer to the list\n",
        "    results.append({\n",
        "        'user_id': user_id,\n",
        "        'brands_interacted': user_data['brand'].tolist(),\n",
        "        'next_5_predicted_brands': next_5_predicted_brands\n",
        "    })\n",
        "\n",
        "# Create a DataFrame from the list of results\n",
        "results_df = pd.concat([pd.DataFrame([r]) for r in results], ignore_index=True)\n",
        "\n",
        "# Display the results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8UFOfCsSUMr",
        "outputId": "f83f9739-3cb2-4f31-e074-c487b33bed9d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 448ms/step\n",
            "1/1 [==============================] - 0s 440ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "     user_id                                  brands_interacted  \\\n",
            "0  CUST_3979  [Swiggy, AJIO, Hometown, Spencer's, RedBus, Ka...   \n",
            "1   CUST_678  [Bewakoof, Ezone, SapnaOnline, Behrouz Biryani...   \n",
            "2  CUST_2199  [The Man Company, DogSpot, Reliance Digital, U...   \n",
            "3  CUST_2011  [Colorbar, Crossword, Sangeetha Mobiles, Clear...   \n",
            "4   CUST_879  [CureFit, Kama Ayurveda, FirstCry, Urban Ladde...   \n",
            "5  CUST_3904  [Poorvika Mobiles, VLCC, Medlife, Hopscotch, P...   \n",
            "6  CUST_2521  [Crossword, Spencer's, Snapdeal, More Supermar...   \n",
            "7  CUST_2366         [CureFit, DogSpot, Medlife, Khadi Natural]   \n",
            "8  CUST_3265  [Bewakoof, More Supermarket, UrbanClap, Apollo...   \n",
            "9  CUST_1025  [Lakme, Reliance Digital, Dunzo, CaratLane, Bl...   \n",
            "\n",
            "                             next_5_predicted_brands  \n",
            "0       [Biotique, CureFit, Purplle, Zomato, Clovia]  \n",
            "1    [Flipkart, Faasos, Zivame, Rentomojo, Hometown]  \n",
            "2           [Amazon, Nykaa, Clovia, AJIO, CaratLane]  \n",
            "3  [CaratLane, Lakme, Forest Essentials, TataCliq...  \n",
            "4  [Hometown, DogSpot, Pepperfry, Snapdeal, Bioti...  \n",
            "5  [SUGAR Cosmetics, Goibibo, Lenskart, MedPlus, ...  \n",
            "6  [Flipkart, Lakme, Snapdeal, Amazon, Apollo Pha...  \n",
            "7                                                 []  \n",
            "8  [Lakme, PharmEasy, Amazon, Forest Essentials, ...  \n",
            "9         [Lakme, Dunzo, Lenskart, Flipkart, Faasos]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9YO7cDZ8lFKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uX0IMkYMp79R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}